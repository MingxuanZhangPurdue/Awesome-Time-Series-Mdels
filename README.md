# Awesome-Time-Series-Mdels

## Awsome posts:

[Probabilistic Time Series Forecasting with ðŸ¤— Transformers](https://huggingface.co/blog/time-series-transformers)

[Multivariate Probabilistic Time Series Forecasting with Informe](https://huggingface.co/blog/informer)

[Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)](https://huggingface.co/blog/autoformer)

## Implementations:
[HuggingFace Transformers](https://huggingface.co/docs/transformers/main/en/model_doc/autoformer)

[GluonTS - Probabilistic Time Series Modeling in Python](https://ts.gluon.ai/stable/)

## MLP/Linear-based models:

[N-BEATS](https://arxiv.org/pdf/1905.10437.pdf)(###SOTA)

[N-BEATSx](https://arxiv.org/pdf/2104.05522.pdf)

[N-HiTS](https://arxiv.org/pdf/2201.12886.pdf)(###SOTA)

[Meta-learning Framework with Applications to Zero-shot Time-series Forecasting](https://arxiv.org/pdf/2002.02887.pdf)

[FC-GAGA](https://arxiv.org/pdf/2007.15531.pdf)

[Dlinear](https://arxiv.org/pdf/2205.13504.pdf) (###SOTA)

## RNN-based models:

[DeepAR](https://arxiv.org/pdf/1704.04110.pdf)

[Deep State Space Model](https://papers.nips.cc/paper_files/paper/2018/file/5cf68969fb67aa6082363a6d4e6468e2-Paper.pdf)

[MQRNN](https://arxiv.org/pdf/1711.11053.pdf)

[Recurrent Neural Networks for Time Series Forecasting: Current Status and Future Directions](https://arxiv.org/pdf/1909.00590.pdf)

[SegRNN](https://arxiv.org/pdf/2308.11200.pdf) (###SOTA)

## Transformer-based models:

[Transformers in Time Series: A Survey](https://arxiv.org/pdf/2202.07125.pdf)

[AutoFormer](https://arxiv.org/pdf/2106.13008.pdf) (###SOTA)

[Informer](https://arxiv.org/pdf/2012.07436.pdf)

[FedFormer](https://arxiv.org/pdf/2201.12740.pdf)

[FiLM](https://arxiv.org/pdf/2205.08897.pdf)

[Non-stationary Transformers](https://arxiv.org/pdf/2205.14415.pdf)
